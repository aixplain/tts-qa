{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to postgresql db usingenvironment variable read from vars.env \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# read environment variables from vars.env\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../vars.env\")\n",
    "\n",
    "# connect to postgresql db on localhost, post 5432, using user and password from vars.env\n",
    "\n",
    "import psycopg2\n",
    "import os\n",
    "\n",
    "# Define the database credentials\n",
    "db_host = os.getenv(\"POSTGRES_HOST\")\n",
    "db_name = os.getenv(\"POSTGRES_DB\")\n",
    "db_user = os.getenv(\"POSTGRES_USER\")\n",
    "db_password = os.getenv(\"POSTGRES_PWD\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove folders under/data/tts-qa/share_*'that starts with share \n",
    "\n",
    "# !rm -rf /data/tts-qa/share_* # be careful with this command, it will remove all folders under /data/tts-qa/share_* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_hours = 20\n",
    "dataset_str = 'German(Dorothee)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the path to the SQL scriptorder by sample.wer desc \n",
    "sql_script = f\"\"\"\n",
    "SELECT\n",
    "    sample.id,\n",
    "    sample.filename,\n",
    "    sample.local_trimmed_path,\n",
    "    sample.local_path,\n",
    "    COALESCE(annotation.final_text, sample.original_text) AS text,\n",
    "    CASE WHEN annotation.final_text IS NULL THEN sample.wer END AS wer,\n",
    "    sample.duration AS duration\n",
    "FROM sample\n",
    "LEFT JOIN annotation ON sample.id = annotation.sample_id AND annotation.status = 'Reviewed'\n",
    "JOIN dataset ON sample.dataset_id = dataset.id\n",
    "WHERE dataset.name LIKE '%' || '{dataset_str}' || '%' and sample.asr_text is not null and sample.trimmed_audio_duration > 0;\n",
    "\"\"\"\n",
    "\n",
    "# Connect to the database\n",
    "conn = psycopg2.connect(\n",
    "    host=db_host,\n",
    "    database=db_name,\n",
    "    user=db_user,\n",
    "    password=db_password\n",
    ")\n",
    "\n",
    "# Execute the SQL script into pandas dataframe with column names\n",
    "df = pd.read_sql_query(sql_script, conn)\n",
    "df['wer'] = df['wer'].fillna(0)\n",
    "df.sort_values(by=['wer'], inplace=True, ascending=True)\n",
    "# df = df[df['wer'] <=0.5]\n",
    "df.dropna(inplace=True)\n",
    "# get 10 hours of audio with lowest wer\n",
    "# find index that the sum of duration is 10 hours\n",
    "\n",
    "cutoff_idx = df['duration'].cumsum().searchsorted(total_hours*60*60)\n",
    "df_share = df.iloc[:cutoff_idx]\n",
    "\n",
    "# make a share fodler\n",
    "share_folder = f\"/data/tts-qa/share_{total_hours}h\"\n",
    "if not os.path.exists(share_folder):\n",
    "    os.mkdir(share_folder)\n",
    "\n",
    "# create a language folder under it \n",
    "if \"English\" in dataset_str:\n",
    "    dataset = \"English\"\n",
    "elif \"Spanish\" in dataset_str:\n",
    "    dataset = \"Spanish\"\n",
    "elif \"German\" in dataset_str:\n",
    "    dataset = \"German\"\n",
    "elif \"French\" in dataset_str:\n",
    "    dataset = \"French\"\n",
    "elif \"Italian\" in dataset_str:\n",
    "    dataset = \"Italian\"\n",
    "\n",
    "lang_folder = os.path.join(share_folder, dataset)\n",
    "if not os.path.exists(lang_folder):\n",
    "    os.mkdir(lang_folder)\n",
    "\n",
    "# create \"wav\" folder under the language folder\n",
    "wav_folder = os.path.join(lang_folder, \"wavs\")\n",
    "if not os.path.exists(wav_folder):\n",
    "    os.mkdir(wav_folder)\n",
    "\n",
    "# copy audio files to the language folder\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "for index, row in  tqdm(df_share.iterrows(), total=df_share.shape[0]):\n",
    "    shutil.copy(row['local_path'], wav_folder)\n",
    "\n",
    "# drop the local_trimmed_path  and wer, id columns\n",
    "df_share_clean = df_share.drop(['local_path', 'wer', 'id'], axis=1)\n",
    "# create a csv file with the same name as the language folder\n",
    "# sort on by filename\n",
    "df_share_clean.sort_values(by=['filename'], inplace=True, ascending=True)\n",
    "df_share_clean.to_csv(os.path.join(lang_folder, dataset + \".csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(f\"/data/tts-qa/share_{total_hours}h/{dataset}/{dataset}.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_share_clean.duration.sum() / 60 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_share.sort_values(by=['wer'], inplace=True, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_share.wer.plot.hist(bins=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Bash Script for Sharing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write down a bash script to go the /data/tts-qa and zip all the folders in a for loop \n",
    "# then upload the zip file to s3://user-ahmet/translated-Spanish-Italian-French-10h.zip\n",
    "\n",
    "with open(os.path.join('/data/tts-qa', \"zip.sh\"), \"w\") as f:\n",
    "    f.write(\"#!/bin/bash\\n\")\n",
    "    f.write(f\"cd /data/tts-qa/share_{total_hours}h\\n\")\n",
    "    \n",
    "    f.write(\"for d in */ ; do\\n\")\n",
    "    # add logging \n",
    "    f.write(\"    echo \\\"zipping $d\\\"\\n\")\n",
    "    # get the name \n",
    "    f.write(\"    folder=${d%/}\\n\")\n",
    "    f.write(\"    zip -r $folder.zip $d\\n\")\n",
    "    f.write(\"done\\n\")\n",
    "    # include ony zip\n",
    "    f.write(f\"aws s3 cp --recursive  --exclude \\\"*\\\" --include \\\"*.zip\\\" ./ s3://user-ahmet/{dataset}-{total_hours}h/\\n\")\n",
    "    f.write(\"echo \\\"done\\\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loisten audio\n",
    "import IPython.display as ipd\n",
    "\n",
    "\n",
    "index = -3\n",
    "print(df_share.iloc[index][\"filename\"])\n",
    "print(df_share.iloc[index][\"text\"])\n",
    "ipd.Audio(df_share.iloc[index][\"local_trimmed_path\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(df_share.iloc[index][\"local_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_share.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corpus-insight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
