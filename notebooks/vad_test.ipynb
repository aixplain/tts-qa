{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from pyannote.audio import Model\n",
    "from pyannote.audio.pipelines import VoiceActivityDetection\n",
    "\n",
    "\n",
    "from src.logger import root_logger\n",
    "\n",
    "\n",
    "app_logger = root_logger.getChild(\"alignment_utils\")\n",
    "\n",
    "\n",
    "def edit_distance(s1, s2):\n",
    "    return editdistance.eval(s1, s2)\n",
    "\n",
    "\n",
    "def format_int(i):\n",
    "    return str(i).zfill(8)\n",
    "\n",
    "\n",
    "modelPyannote = Model.from_pretrained(\"pyannote/segmentation\", use_auth_token=\"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\")\n",
    "\n",
    "\n",
    "padding = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = VoiceActivityDetection(segmentation=modelPyannote)\n",
    "HYPER_PARAMETERS = {\n",
    "    # onset/offset activation thresholds\n",
    "    \"onset\": 0.5,\n",
    "    \"offset\": 0.5,\n",
    "    # remove speech regions shorter than that many seconds.\n",
    "    \"min_duration_on\": 0.0,\n",
    "    # fill non-speech regions shorter than that many seconds.\n",
    "    \"min_duration_off\": 0.0,\n",
    "}\n",
    "pipeline.instantiate(HYPER_PARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"/home/ubuntu/repos/tts-qa/MariahProctorTTSGerman.wav\"\n",
    "filename = \"/home/ubuntu/repos/tts-qa/notebooks/test-eng-57.wav\"\n",
    "vad = pipeline(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from pydub import AudioSegment\n",
    "\n",
    "data = AudioSegment.from_file(filename)\n",
    "\n",
    "timeline = vad.get_timeline().support()\n",
    "for segment in tqdm(timeline):\n",
    "    start, end = list(segment)\n",
    "    start = max(0, start - padding)\n",
    "    end = min(end + padding, len(data) / 1000)\n",
    "    seg = {}\n",
    "    seg[\"SegmentStart\"] = start\n",
    "    seg[\"SegmentEnd\"] = end\n",
    "    outputAudio = AudioSegment.empty()\n",
    "    outputAudio += data[seg[\"SegmentStart\"] * 1000 : seg[\"SegmentEnd\"] * 1000]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start, end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SILERIO VAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sampling rate of the audio file\n",
    "import soundfile as sf\n",
    "\n",
    "audio, sr = sf.read(filename)\n",
    "\n",
    "print(\"sampling rate:\", sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to 16kHz\n",
    "from pydub import AudioSegment\n",
    "\n",
    "sound = AudioSegment.from_file(filename)\n",
    "sound = sound.set_frame_rate(16000)\n",
    "sound.export(filename, format=\"wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "from IPython.display import Audio\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_RATE = 16_000\n",
    "USE_ONNX = False # change this to True if you want to test onnx model\n",
    "model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',\n",
    "                              model='silero_vad',\n",
    "                              force_reload=True,\n",
    "                              onnx=USE_ONNX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(get_speech_timestamps,\n",
    " save_audio,\n",
    " read_audio,\n",
    " VADIterator,\n",
    " collect_chunks) = utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav = read_audio(filename, sampling_rate=SAMPLING_RATE)\n",
    "# get speech timestamps from full audio file\n",
    "speech_timestamps = get_speech_timestamps(wav, model, sampling_rate=SAMPLING_RATE)\n",
    "pprint(speech_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(speech_timestamps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whisper VAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper_timestamped as whisperts\n",
    "\n",
    "audio = whisperts.load_audio(filename)\n",
    "\n",
    "model = whisperts.load_model(\"medium\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = whisperts.transcribe(model, data, vad=True, detect_disfluencies=False, language=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"segments\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corpus-insight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
