{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing English dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1849656/3878092444.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(sql_script, conn)\n",
      "100%|██████████| 13829/13829 [01:08<00:00, 200.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# connect to postgresql db usingenvironment variable read from vars.env \n",
    "\n",
    "import os\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# read environment variables from vars.env\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../vars.env\")\n",
    "\n",
    "# connect to postgresql db on localhost, post 5432, using user and password from vars.env\n",
    "\n",
    "import psycopg2\n",
    "import os\n",
    "\n",
    "# Define the database credentials\n",
    "db_host = os.getenv(\"POSTGRES_HOST\")\n",
    "db_name = os.getenv(\"POSTGRES_DB\")\n",
    "db_user = os.getenv(\"POSTGRES_USER\")\n",
    "db_password = os.getenv(\"POSTGRES_PWD\")\n",
    "\n",
    "\n",
    "for dataset in [\"English\"]:\n",
    "    print(f\"Processing {dataset} dataset\")\n",
    "    # Define the path to the SQL scriptorder by sample.wer desc \n",
    "    sql_script = f\"\"\"\n",
    "    SELECT sample.id, sample.filename, sample.local_trimmed_path, sample.original_text as text, sample.wer, sample.trimmed_audio_duration as duration\n",
    "    FROM sample\n",
    "    JOIN dataset ON sample.dataset_id = dataset.id\n",
    "    WHERE dataset.name LIKE '%' || '{dataset}' || '%';\n",
    "    \"\"\"\n",
    "\n",
    "    # Connect to the database\n",
    "    conn = psycopg2.connect(\n",
    "        host=db_host,\n",
    "        database=db_name,\n",
    "        user=db_user,\n",
    "        password=db_password\n",
    "    )\n",
    "\n",
    "    # Execute the SQL script into pandas dataframe with column names\n",
    "    df = pd.read_sql_query(sql_script, conn)\n",
    "    df.sort_values(by=['wer'], inplace=True, ascending=True)\n",
    "\n",
    "    # get 10 hours of audio with lowest wer\n",
    "    # find index that the sum of duration is 10 hours\n",
    "\n",
    "    inx_10h = df['duration'].cumsum().searchsorted(10*60*60)\n",
    "    df_10h = df.iloc[:inx_10h]\n",
    "\n",
    "\n",
    "    # make a share fodler\n",
    "    share_folder = \"/data/tts-qa/share_10h\"\n",
    "    if not os.path.exists(share_folder):\n",
    "        os.mkdir(share_folder)\n",
    "\n",
    "    # create a language folder under it \n",
    "    lang_folder = os.path.join(share_folder, dataset)\n",
    "    if not os.path.exists(lang_folder):\n",
    "        os.mkdir(lang_folder)\n",
    "\n",
    "    # create \"wav\" folder under the language folder\n",
    "    wav_folder = os.path.join(lang_folder, \"wavs\")\n",
    "    if not os.path.exists(wav_folder):\n",
    "        os.mkdir(wav_folder)\n",
    "\n",
    "    # copy audio files to the language folder\n",
    "    import shutil\n",
    "    from tqdm import tqdm\n",
    "    for index, row in  tqdm(df_10h.iterrows(), total=df_10h.shape[0]):\n",
    "        shutil.copy(row['local_trimmed_path'], wav_folder)\n",
    "\n",
    "    # drop the local_trimmed_path  and wer, id columns\n",
    "    df_10h_clean = df_10h.drop(['local_trimmed_path', 'wer', 'id'], axis=1)\n",
    "    # create a csv file with the same name as the language folder\n",
    "    # sort on by filename\n",
    "    df_10h_clean.sort_values(by=['filename'], inplace=True, ascending=True)\n",
    "    df_10h_clean.to_csv(os.path.join(lang_folder, dataset + \".csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write down a bash script to go the /data/tts-qa and zip all the folders in a for loop \n",
    "# then upload the zip file to s3://user-ahmet/translated-Spanish-Italian-French-10h.zip\n",
    "\n",
    "with open(os.path.join('/data/tts-qa', \"zip.sh\"), \"w\") as f:\n",
    "    f.write(\"#!/bin/bash\\n\")\n",
    "    f.write(\"cd /data/tts-qa/share_10h\\n\")\n",
    "    \n",
    "    f.write(\"for d in */ ; do\\n\")\n",
    "    # add logging \n",
    "    f.write(\"    echo \\\"zipping $d\\\"\\n\")\n",
    "    # get the name \n",
    "    f.write(\"    folder=${d%/}\\n\")\n",
    "    f.write(\"    zip -r $folder.zip $d\\n\")\n",
    "    f.write(\"done\\n\")\n",
    "    # include ony zip\n",
    "    f.write(\"aws s3 cp --recursive  --exclude \\\"*\\\" --include \\\"*.zip\\\" ./ s3://user-ahmet/translated-Spanish-Italian-French-10h/\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EN00000212.wav</td>\n",
       "      <td>I wish her to be brought to me at once.</td>\n",
       "      <td>2.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EN00000521.wav</td>\n",
       "      <td>Well, I can go back to work now.</td>\n",
       "      <td>2.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EN00000660.wav</td>\n",
       "      <td>You look as if you've just seen a ghost, old man.</td>\n",
       "      <td>2.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EN00000732.wav</td>\n",
       "      <td>Not too soon for me to see the stars of home.</td>\n",
       "      <td>2.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EN00002023.wav</td>\n",
       "      <td>We party, but the world will continue without us.</td>\n",
       "      <td>3.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename                                               text  duration\n",
       "0  EN00000212.wav            I wish her to be brought to me at once.      2.24\n",
       "1  EN00000521.wav                   Well, I can go back to work now.      2.20\n",
       "2  EN00000660.wav  You look as if you've just seen a ghost, old man.      2.84\n",
       "3  EN00000732.wav      Not too soon for me to see the stars of home.      2.44\n",
       "4  EN00002023.wav  We party, but the world will continue without us.      3.12"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_en = pd.read_csv(\"/data/tts-qa/share_10h/English/English.csv\")\n",
    "df_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.999777777777776"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en.duration.sum() / 60 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corpus-insight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
