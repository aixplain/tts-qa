{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from glob import glob\n",
    "\n",
    "import editdistance\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyannote.audio import Model\n",
    "from pyannote.audio.pipelines import VoiceActivityDetection\n",
    "from pyannote.core import notebook, Segment\n",
    "from pydub import AudioSegment\n",
    "from tqdm import tqdm\n",
    "from whisper_model import WhisperASR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.io.wavfile as wav\n",
    "import scipy.signal as signal\n",
    "\n",
    "import tempfile\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "from IPython.display import Audio\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim the audio using start end end time in secs\n",
    "def trim_audio(path, start, end, out_path):\n",
    "    sound = AudioSegment.from_file(path, format=\"wav\")\n",
    "    # make sure that the start and end are in between the audio duration\n",
    "    start = max(0, start)\n",
    "    end = min(end, len(sound) / 1000)\n",
    "    trimmed_sound = sound[start * 1000 : end * 1000]\n",
    "    trimmed_sound.export(out_path, format=\"wav\")\n",
    "    return out_path, start, end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files_folder = \"/data/tts-qa/tts-data/French(Dorsaf)/trimmed\"\n",
    "files_folder = \"/data/tts-qa/tts-data/German(Dorothee)/trimmed\"\n",
    "# files_folder = \"/data/tts-qa/tts-data/English(Melynda)/trimmed\"\n",
    "# files_folder = \"/data/tts-qa/tts-data/Italian(Martina) Deliverable 3/trimmed\"\n",
    "# files_folder = \"/data/tts-qa/tts-data/Spanish(Violeta) Deliverable 3/trimmed\"\n",
    "\n",
    "\n",
    "files = glob(os.path.join(files_folder, \"*.wav\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select  files\n",
    "\n",
    "np.random.seed(10)\n",
    "selected_files = np.random.choice(files, 50, replace=False)\n",
    "\n",
    "# selected_files = [\n",
    "#     \"/data/tts-qa/tts-data/French(Dorsaf)/trimmed/FR00000026.wav\",\n",
    "#     \"/data/tts-qa/tts-data/French(Dorsaf)/trimmed/FR00000032.wav\",\n",
    "#     \"/data/tts-qa/tts-data/French(Dorsaf)/trimmed/FR00000033.wav\",\n",
    "#     \"/data/tts-qa/tts-data/French(Dorsaf)/trimmed/FR00000035.wav\",\n",
    "#     \"/data/tts-qa/tts-data/French(Dorsaf)/trimmed/FR00001001.wav\",\n",
    "# ]\n",
    "\n",
    "\n",
    "# rare_cases = [\n",
    "#     \"/data/tts-qa/tts-data/French(Dorsaf)/raw/FR00000907.wav\",\n",
    "#     \"/data/tts-qa/tts-data/French(Dorsaf)/raw/FR00000115.wav\",\n",
    "#     \"/data/tts-qa/tts-data/French(Dorsaf)/raw/FR00000169.wav\",\n",
    "#     \"/data/tts-qa/tts-data/French(Dorsaf)/raw/FR00000952.wav\",\n",
    "#     \"/data/tts-qa/tts-data/French(Dorsaf)/raw/FR00000584.wav\",\n",
    "#     \"/data/tts-qa/tts-data/French(Dorsaf)/raw/FR00000911.wav\",\n",
    "#     \"/data/tts-qa/tts-data/French(Dorsaf)/raw/FR00001238.wav\",\n",
    "#     \"/data/tts-qa/tts-data/French(Dorsaf)/raw/FR00000979.wav\",\n",
    "# ]\n",
    "# selected_files= rare_cases\n",
    "\n",
    "# selected_files = [\n",
    "#     \"/data/tts-qa/tts-data/German(Dorothee)/trimmed/DE00080623.wav\",\n",
    "#     \"/data/tts-qa/tts-data/German(Dorothee)/trimmed/DE00069958.wav\",\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.audio import CustomVAD\n",
    "my_custom_vad = CustomVAD(pyannote_model_path=\"pyannote/segmentation\", silero_model_path=\"snakers4/silero-vad\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run for selected files and plot\n",
    "for file in selected_files[:10]:\n",
    "    response = my_custom_vad.process_file(file)\n",
    "\n",
    "    # load the waveform\n",
    "    waveform = response[\"resampled_waveform\"]\n",
    "    # Calculate time vector\n",
    "    time_vector = np.linspace(0, len(waveform) / my_custom_vad.SAMPLING_RATE, num=len(waveform))\n",
    "\n",
    "    # plot \n",
    "    fig = plt.figure(figsize=(20, 5), dpi=50)\n",
    "    plt.yticks([])\n",
    "    plt.plot(time_vector, waveform)\n",
    "\n",
    "    # add the filename as title\n",
    "    plt.title(os.path.basename(file))\n",
    "\n",
    "    # plot pyannote\n",
    "    plt.axvspan(response[\"pyannote_segment\"][0], response[\"pyannote_segment\"][1], color=\"green\", alpha=0.3, label=\"PYANNOTE\")\n",
    "\n",
    "    # plot silero\n",
    "    plt.axvspan(response[\"silero_segment\"][0], response[\"silero_segment\"][1], color=\"red\", alpha=0.3, label=\"SILERO-VAD\")\n",
    "\n",
    "    # plot custom\n",
    "    plt.axvspan(response[\"custom_segment\"][0], response[\"custom_segment\"][1], color=\"black\", alpha=0.3, label=\"MY_CUSTOM_VAD\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_start, trim_end = tuple(response['custom_segment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corpus-insight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
