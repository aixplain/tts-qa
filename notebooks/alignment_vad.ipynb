{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from glob import glob\n",
    "\n",
    "import editdistance\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyannote.audio import Model\n",
    "from pyannote.audio.pipelines import VoiceActivityDetection\n",
    "from pydub import AudioSegment\n",
    "from tqdm import tqdm\n",
    "from whisper_model import WhisperASR\n",
    "\n",
    "\n",
    "def edit_distance(s1, s2):\n",
    "    return editdistance.eval(s1, s2)\n",
    "\n",
    "\n",
    "def format_int(i):\n",
    "    return str(i).zfill(8)\n",
    "\n",
    "\n",
    "# trim the audio using start end end time in secs\n",
    "def trim_audio(path, start, end, out_path):\n",
    "    sound = AudioSegment.from_file(path, format=\"wav\")\n",
    "    # make sure that the start and end are in between the audio duration\n",
    "    start = max(0, start)\n",
    "    end = min(end, len(sound) / 1000)\n",
    "    trimmed_sound = sound[start * 1000 : end * 1000]\n",
    "    trimmed_sound.export(out_path, format=\"wav\")\n",
    "    return out_path, start, end\n",
    "\n",
    "\n",
    "modelPyannote = Model.from_pretrained(\"pyannote/segmentation\", use_auth_token=\"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\")\n",
    "\n",
    "pipeline = VoiceActivityDetection(segmentation=modelPyannote)\n",
    "HYPER_PARAMETERS = {\n",
    "    # onset/offset activation thresholds\n",
    "    \"onset\": 0.5,\n",
    "    \"offset\": 0.5,\n",
    "    # remove speech regions shorter than that many seconds.\n",
    "    \"min_duration_on\": 0.0,\n",
    "    # fill non-speech regions shorter than that many seconds.\n",
    "    \"min_duration_off\": 0.05,\n",
    "}\n",
    "pipeline.instantiate(HYPER_PARAMETERS)\n",
    "\n",
    "\n",
    "batches = [\"batches_French8_2/\"]\n",
    "padding = 0.25\n",
    "\n",
    "\n",
    "print(\"Loading Whisper model...\")\n",
    "\n",
    "lang_map = {\n",
    "    \"en\": \"english\",\n",
    "    \"fr\": \"french\",\n",
    "    \"es\": \"spanish\",\n",
    "    \"de\": \"german\",\n",
    "    \"it\": \"italian\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"de\"\n",
    "folder = \"./test_folder_vad/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# whisper_model = WhisperASR(model_size=\"large-v2\", language=lang_map[language])\n",
    "whisper_model = WhisperASR(model_size=\"large-v2\", language=lang_map[language])\n",
    "whisper_model.load()\n",
    "print(f\"Processing folder {folder}\")\n",
    "filenames = glob(folder + \"*.wav\")\n",
    "for filename in filenames:\n",
    "    print(f\"Processing {filename}\")\n",
    "    segments_path = filename + \".vad.bin\"\n",
    "    if os.path.exists(segments_path):\n",
    "        print(f\"Detected segments file {filename}\")\n",
    "        vad_segments = pickle.load(open(segments_path, \"rb\"))\n",
    "    else:\n",
    "        print(f\"Generating segments file {filename}\")\n",
    "        vad_segments = pipeline(filename)\n",
    "        print(f\"Saving segments for {filename}\")\n",
    "        with open(segments_path, \"wb\") as f:\n",
    "            pickle.dump(vad_segments, f)\n",
    "        print(f\"Saved segments for {filename} to {segments_path}\")\n",
    "\n",
    "    data = AudioSegment.from_file(filename)\n",
    "    \n",
    "    # read start_loc and end_loc from wav file name  using regex\n",
    "    if language == \"fr\":\n",
    "        start_loc = int(re.search(r\"From (\\d+) -\", filename).group(1))\n",
    "        end_loc = int(re.search(r\"- (\\d+)\", filename).group(1))\n",
    "    elif language == \"en\":\n",
    "        # reg sdhould work on EN00000003-EN00000012\n",
    "        start_loc = int(re.search(r\"EN(\\d+)-\", filename).group(1))\n",
    "        end_loc = int(re.search(r\"-EN(\\d+)\", filename).group(1))\n",
    "    elif language == \"de\":\n",
    "        # reg sdhould work on start_1-end_500\n",
    "        start_loc = int(re.search(r\"start_DE(\\d+)-\", filename).group(1))\n",
    "        end_loc = int(re.search(r\"-end_DE(\\d+)\", filename).group(1))\n",
    "\n",
    "    print(f\"start_loc: {start_loc}, end_loc: {end_loc}\")\n",
    "\n",
    "    sentences = {}\n",
    "    inverseSentences = {}\n",
    "    df_sentences = pd.read_csv(f\"{language} - {language}.csv\")\n",
    "    id_int = df_sentences[\"unique_identifier\"].apply(lambda x: int(x[2:]))\n",
    "    df_sentences[\"id_int\"] = id_int\n",
    "    df_sentences.set_index(\"id_int\", inplace=True)\n",
    "    # include only ids in between start_loc and end_loc\n",
    "    df_sentences = df_sentences.loc[start_loc:end_loc]\n",
    "\n",
    "    print(f\"There are {len(df_sentences)} sentences in this range\")\n",
    "    for index, row in df_sentences.iterrows():\n",
    "        sentenceNum = int(index)\n",
    "        sentence = row[\"text\"]\n",
    "        sentences[sentenceNum] = sentence\n",
    "        if sentence not in inverseSentences:\n",
    "            inverseSentences[sentence] = sentenceNum\n",
    "        else:\n",
    "            tmp = sentence\n",
    "            while tmp in inverseSentences:\n",
    "                tmp += \" _\"\n",
    "            inverseSentences[tmp] = sentenceNum\n",
    "\n",
    "    sentenceNumber = -1\n",
    "    segments = {}\n",
    "    if os.path.exists(filename + \".segments.json\"):\n",
    "        print(f\"Detected segments for {filename} - loading from file\")\n",
    "        segments = json.load(open(filename + \".segments.json\"))\n",
    "    else:\n",
    "        print(f\"Running ASR for {filename}\")\n",
    "        \n",
    "        timeline = vad_segments.get_timeline().support()\n",
    "        for segment in tqdm(timeline):\n",
    "            start, end = list(segment)\n",
    "            start = max(0, start - padding)\n",
    "            end = min(end + padding, len(data) / 1000)\n",
    "            seg = {}\n",
    "            seg[\"SegmentStart\"] = start\n",
    "            seg[\"SegmentEnd\"] = end\n",
    "            outputAudio = AudioSegment.empty()\n",
    "            outputAudio += data[seg[\"SegmentStart\"] * 1000 : seg[\"SegmentEnd\"] * 1000]\n",
    "            outputAudio.export(folder + \"TMP/tmp.wav\", format=\"wav\")\n",
    "            # run ASR\n",
    "            try:\n",
    "                result = whisper_model.predict({\"instances\": [{\"url\": folder + \"TMP/tmp.wav\"}]})\n",
    "                asr = result[\"predictions\"][0]\n",
    "                seg[\"asr\"] = asr\n",
    "            except:\n",
    "                seg[\"asr\"] = \"\"\n",
    "                pass\n",
    "            segments[start] = seg\n",
    "        # save segments\n",
    "        print(f\"Saving segments for {filename}\")\n",
    "        with open(filename + \".segments.json\", \"w\") as fout:\n",
    "            json.dump(segments, fout, indent=4)\n",
    "        print(f\"Saved segments for {filename}\")\n",
    "\n",
    "    print(f\"Matching segments to sentences for {filename}\")\n",
    "    segments_list = [v for k, v in segments.items()]\n",
    "    sentences_list = [v for k, v in sentences.items()]\n",
    "    distances_matrix = np.ones((len(segments_list), len(sentences))) * 1000\n",
    "\n",
    "    for ik in range(len(segments_list)):\n",
    "        for jk, sentence in enumerate(sentences_list):\n",
    "            try:\n",
    "                distances_matrix[ik, jk] = edit_distance(segments_list[ik][\"asr\"], sentence) / min(len(segments_list[ik][\"asr\"]), len(sentence))\n",
    "            except:\n",
    "                distances_matrix[ik, jk] = np.inf\n",
    "\n",
    "    # get the best match for each segment\n",
    "    best_matches = np.argmin(distances_matrix, axis=1)\n",
    "\n",
    "    # # make a dataframe\n",
    "    columns = [\"status\", \"filename\", \"sentenceNumber\", \"sentence\", \"asr\", \"start\", \"end\", \"ed_dist\", \"len_dif\"]\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    best_matched_sentences = [sentences_list[k] for k in best_matches]\n",
    "\n",
    "    # print the results\n",
    "    for ik in range(len(segments_list)):\n",
    "        asr = segments_list[ik][\"asr\"]\n",
    "        sentence = best_matched_sentences[ik]\n",
    "        ed_dist = distances_matrix[ik, best_matches[ik]]\n",
    "        try:\n",
    "            len_dif = abs(len(asr) - len(sentence)) / min(len(asr), len(sentence))\n",
    "        except:\n",
    "            len_dif = np.inf\n",
    "        start = segments_list[ik][\"SegmentStart\"]\n",
    "        end = segments_list[ik][\"SegmentEnd\"]\n",
    "        sentenceNumber = inverseSentences[sentence]\n",
    "        if ed_dist < 0.25 and len_dif < 0.15:\n",
    "            status = \"assigned\"\n",
    "        else:\n",
    "            status = \"not_assigned\"\n",
    "\n",
    "        row = {\n",
    "            \"status\": status,\n",
    "            \"filename\": filename,\n",
    "            \"sentenceNumber\": sentenceNumber,\n",
    "            \"sentence\": sentence,\n",
    "            \"asr\": asr,\n",
    "            \"start\": start,\n",
    "            \"end\": end,\n",
    "            \"ed_dist\": ed_dist,\n",
    "            \"len_dif\": len_dif,\n",
    "        }\n",
    "        df = df.append(row, ignore_index=True)\n",
    "    # if there is inf  drop it\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    print(f\"Assigned {len(df[df.status=='assigned'])} segments\")\n",
    "    print(f\"Not assigned {len(df[df.status=='not_assigned'])} segments\")\n",
    "\n",
    "    # if there are multiple rows with same sentenceNumber take the last one and drop the rest\n",
    "    df = df.sort_values(by=[\"sentenceNumber\"])\n",
    "    df = df.drop_duplicates(subset=[\"sentenceNumber\"], keep=\"last\")\n",
    "\n",
    "    print(f\"Status counts for {filename}:\")\n",
    "    print(df.status.value_counts())\n",
    "    df.to_csv(filename + \".csv\", index=False)\n",
    "\n",
    "    # create a folder for wav files\n",
    "    wav_folder = os.path.join(folder, os.path.basename(filename).replace(\".wav\", \"\"))\n",
    "    if os.path.exists(wav_folder):\n",
    "        print(f\"Folder {wav_folder} already exists, skipping\")\n",
    "        continue\n",
    "    os.makedirs(wav_folder, exist_ok=True)\n",
    "\n",
    "    # create \"assigned\" and \"not_assigned\" folders\n",
    "    os.makedirs(os.path.join(wav_folder, \"assigned\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(wav_folder, \"not_assigned\"), exist_ok=True)\n",
    "\n",
    "    # for each row in the dataframe if the status is assigned, create a wav file with the start and end times of the segment\n",
    "    # if not assigned, create a wav file with the start and end times of the segment\n",
    "    print(f\"Trimming audio for {filename}, it will be saved in {wav_folder}\")\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        start = row[\"start\"]\n",
    "        end = row[\"end\"]\n",
    "        asr = row[\"asr\"]\n",
    "        sentence = row[\"sentence\"]\n",
    "        status = row[\"status\"]\n",
    "        if status == \"assigned\":\n",
    "            wav_path = os.path.join(wav_folder, \"assigned\", f\"{language.upper()}\" + format_int(row[\"sentenceNumber\"]) + \".wav\")\n",
    "        else:\n",
    "            wav_path = os.path.join(wav_folder, \"not_assigned\", f\"{language.upper()}\" + format_int(row[\"sentenceNumber\"]) + \".wav\")\n",
    "\n",
    "        outpath, start, end = trim_audio(filename, start, end, wav_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corpus-insight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
